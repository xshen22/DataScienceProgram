{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This practice will cover learning points in class2\n",
    "### 1 - Fit MLR model in python with sklearn and statesmodel packages\n",
    "### 2 - Model Selection\n",
    "### 3 - Weighted regression\n",
    "### 4 - Regularization, L1 and L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dmba import stepwise_selection\n",
    "from dmba import AIC_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths to data sets. If you don't keep your data in the same directory as the code, adapt the path names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path('.').resolve().parents[1] / 'YOUR/SUBDIRECTORY'\n",
    "\n",
    "HOUSE_CSV = DATA / 'house_sales.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(DATA)\n",
    "# print(HOUSE_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data read and train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houseall = pd.read_csv(HOUSE_CSV, sep='\\t')\n",
    "\n",
    "house, house_test = train_test_split(houseall, test_size=0.2)\n",
    "\n",
    "print(house.head())\n",
    "print(house.shape)\n",
    "\n",
    "print(house_test.head())\n",
    "print(house_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `LinearRegression` model from _scikit-learn_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Multiple Linear Regression (SKlearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ['AdjSalePrice', 'SqFtTotLiving', 'SqFtLot', 'Bathrooms', \n",
    "          'Bedrooms', 'BldgGrade']\n",
    "\n",
    "print(house[subset].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(house.head())\n",
    "print(house.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms', \n",
    "              'Bedrooms', 'BldgGrade']\n",
    "outcome = 'AdjSalePrice'\n",
    "\n",
    "house_lm = LinearRegression()\n",
    "house_lm.fit(house[predictors], house[outcome])\n",
    "\n",
    "print(f'Intercept: {house_lm.intercept_:.3f}')\n",
    "print('Coefficients:')\n",
    "for name, coef in zip(predictors, house_lm.coef_):\n",
    "    print(f' {name}: {coef}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the Model with performance KPIs\n",
    "_Scikit-learn_ provides a number of metrics to determine the quality of a model. Here we use the `r2_score` and `RMSE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = house_lm.predict(house[predictors])\n",
    "RMSE = np.sqrt(mean_squared_error(house[outcome], fitted))\n",
    "r2 = r2_score(house[outcome], fitted)\n",
    "print(f'RMSE: {RMSE:.0f}')\n",
    "print(f'r2: {r2:.4f}')\n",
    "\n",
    "fitted_test = house_lm.predict(house_test[predictors])\n",
    "RMSE_test = np.sqrt(mean_squared_error(house_test[outcome], fitted_test))\n",
    "r2 = r2_score(house_test[outcome], fitted_test)\n",
    "print(f'RMSE_test: {RMSE:.0f}')\n",
    "print(f'r2_test: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Multiple Linear Regression (statsmodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While _scikit-learn_ provides a variety of different metrics, _statsmodels_ provides a more in-depth analysis of the linear regression model. This package has two different ways of specifying the model, one that is similar to _scikit-learn_ and one that allows specifying _R_-style formulas. Here we use the first approach. As _statsmodels_ doesn't add an intercept automaticaly, we need to add a constant column with value 1 to the predictors. We can use the _pandas_ method assign for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_sm = sm.OLS(house[outcome], house[predictors].assign(const=1))\n",
    "results = mlr_sm.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations between predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = house[predictors].corr()\n",
    "print(\"Correlation Matrix \\n {}\".format(corr))\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Model Selection and Stepwise Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms', 'Bedrooms',\n",
    "              'BldgGrade', 'PropertyType', 'NbrLivingUnits',\n",
    "              'SqFtFinBasement', 'YrBuilt', 'YrRenovated', \n",
    "              'NewConstruction']\n",
    "\n",
    "print(house[predictors].head())\n",
    "\n",
    "print(\"\\n PropertyType List \\n{}\".format(house['PropertyType'].value_counts(dropna=False)))\n",
    "\n",
    "X = pd.get_dummies(house[predictors], drop_first=True)\n",
    "X['NewConstruction'] = [1 if nc else 0 for nc in X['NewConstruction']]\n",
    "\n",
    "print(\"\\nPredictors after nominal varibale(s) treatment: {} \\n\\n\".format(X.shape))\n",
    "\n",
    "house_full = sm.OLS(house[outcome], X.assign(const=1))\n",
    "results = house_full.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `stepwise_selection` method from the _dmba_ package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = house[outcome]\n",
    "\n",
    "def train_model(variables):\n",
    "    if len(variables) == 0:\n",
    "        return None\n",
    "    model = LinearRegression()\n",
    "    model.fit(X[variables], y)\n",
    "    return model\n",
    "\n",
    "def score_model(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(y, [y.mean()] * len(y), model, df=1)\n",
    "    return AIC_score(y, model.predict(X[variables]), model)\n",
    "\n",
    "best_model, best_variables = stepwise_selection(X.columns, train_model, score_model, \n",
    "                                                verbose=True)\n",
    "\n",
    "print()\n",
    "print(f'Intercept: {best_model.intercept_:.3f}')\n",
    "print('Coefficients:')\n",
    "for name, coef in zip(best_variables, best_model.coef_):\n",
    "    print(f' {name}: {coef}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Weighted regression\n",
    "For the house data recent sale price is more relavent for future prediction, old sale data is less reliable, therefore, we like to emphasis the recent sale data by apply more weight. We will use year the house sale to 2005 as weight.\n",
    "\n",
    "We can calculate the Year from the date column using either a list comprehension or the data frame's `apply` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDocumentDate List \\n{}\".format(house['DocumentDate'].value_counts(dropna=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house['Year'] = [int(date.split('-')[0]) for date in house.DocumentDate]  #list comprehension\n",
    "house['Year'] = house.DocumentDate.apply(lambda d: int(d.split('-')[0]))  # apply()\n",
    "house['Weight'] = house.Year - 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms', \n",
    "              'Bedrooms', 'BldgGrade']\n",
    "outcome = 'AdjSalePrice'\n",
    "\n",
    "house_wt = LinearRegression()\n",
    "house_wt.fit(house[predictors], house[outcome], sample_weight=house.Weight)\n",
    "pd.DataFrame({\n",
    "    'predictor': predictors,\n",
    "    'house_lm': house_lm.coef_,\n",
    "    'house_wt': house_wt.coef_,\n",
    "}).append({\n",
    "    'predictor': 'intercept', \n",
    "    'house_lm': house_lm.intercept_,\n",
    "    'house_wt': house_wt.intercept_,\n",
    "}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = pd.DataFrame({\n",
    "    'abs_residual_lm': np.abs(house_lm.predict(house[predictors]) - house[outcome]),\n",
    "    'abs_residual_wt': np.abs(house_wt.predict(house[predictors]) - house[outcome]),\n",
    "    'Year': house['Year'],\n",
    "})\n",
    "print(residuals.head())\n",
    "axes = residuals.boxplot(['abs_residual_lm', 'abs_residual_wt'], by='Year', figsize=(10, 4))\n",
    "axes[0].set_ylim(0, 300000)\n",
    "\n",
    "print(\"\\n\\nYear   Abs_residual_lm    Abs_residual_wt\")\n",
    "for year, group in residuals.groupby('Year'):\n",
    "    print(year, np.mean(group['abs_residual_lm']), np.mean(group['abs_residual_wt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems only help 2015 prediction reduce the residuale.If we have a recent holdout sample we can test the weight could help for furture prediction or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms', 'Bedrooms',\n",
    "              'BldgGrade', 'PropertyType', 'NbrLivingUnits',\n",
    "              'SqFtFinBasement', 'YrBuilt', 'YrRenovated', \n",
    "              'NewConstruction']\n",
    "\n",
    "outcome = 'AdjSalePrice'\n",
    "\n",
    "print(house[predictors].head())\n",
    "\n",
    "print(\"\\n PropertyType List \\n{}\".format(house['PropertyType'].value_counts(dropna=False)))\n",
    "\n",
    "X_train = pd.get_dummies(house[predictors], drop_first=True)\n",
    "X_train['NewConstruction'] = [1 if nc else 0 for nc in X_train['NewConstruction']]\n",
    "y_train = house[outcome]\n",
    "\n",
    "X_test = pd.get_dummies(house_test[predictors], drop_first=True)\n",
    "X_test['NewConstruction'] = [1 if nc else 0 for nc in X_test['NewConstruction']]\n",
    "y_test = house_test[outcome]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_lm = LinearRegression()\n",
    "house_lm.fit(X_train, y_train)\n",
    "\n",
    "mlr_coefs = dict(\n",
    "    zip(['Intercept'] + X_train.columns.tolist()[:-1], \n",
    "        np.round(np.concatenate((house_lm.intercept_, house_lm.coef_), \n",
    "                                axis=None), 3))\n",
    ")\n",
    "\n",
    "mlr_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_test = house_lm.predict(X_test)\n",
    "MSE_test = np.sqrt(mean_squared_error(y_test, fitted_test))\n",
    "r2 = r2_score(y_test, fitted_test)\n",
    "print(f'regular mlr MSE: {MSE_test:.0f}')\n",
    "print(f'r2_test: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 - Ridge regression (Parameter shrinkage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv = RidgeCV(normalize=True, alphas=np.logspace(-10, 1, 400))\n",
    "ridge_model = ridge_cv.fit(X_train, y_train)\n",
    "ridge_prediction = ridge_model.predict(X_test)\n",
    "ridge_mae = np.mean(np.abs(y_test - ridge_prediction))\n",
    "ridge_coefs = dict(\n",
    "    zip(['Intercept'] + X_train.columns.tolist()[:-1], \n",
    "        np.round(np.concatenate((ridge_model.intercept_, ridge_model.coef_), \n",
    "                                axis=None), 3))\n",
    ")\n",
    "\n",
    "print('Ridge Regression MAE: {}'.format(np.round(ridge_mae, 3)))\n",
    "print('Ridge Regression coefficients:')\n",
    "ridge_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 - Lasso regression (Parameter sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv = LassoCV(normalize=True, alphas=np.logspace(-10, 1, 400))\n",
    "lasso_model = lasso_cv.fit(X_train, y_train)\n",
    "lasso_prediction = lasso_model.predict(X_test)\n",
    "lasso_mae = np.mean(np.abs(y_test - lasso_prediction))\n",
    "lasso_coefs = dict(\n",
    "    zip(['Intercept'] + X_train.columns.tolist()[:-1], \n",
    "        np.round(np.concatenate((lasso_model.intercept_, lasso_model.coef_), axis=None), 3))\n",
    ")\n",
    "\n",
    "print('LASSO MAE: {}'.format(np.round(lasso_mae, 3)))\n",
    "print('LASSO coefficients:')\n",
    "lasso_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compare the three model fits and draw conclusion \n",
    "from the comparision of the three model firt regarding there coefficent difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Show the three model performance on both tran and test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
